# 模型配置
model:
  vocab_size: 1000
  d_model: 128
  num_heads: 4
  d_ff: 512
  num_layers: 2
  max_seq_len: 128
  dropout: 0.1

# 训练配置
training:
  batch_size: 32
  learning_rate: 3e-4
  num_epochs: 50
  grad_clip: 1.0
  weight_decay: 0.01
  device: "cuda"

# 数据配置
data:
  dataset: "tiny_shakespeare"
  seq_len: 128
  train_split: 0.9

# 实验配置
experiment:
  seed: 42
  save_dir: "./results"